# PLDA
LDA（Latent Dirichlet Allocation，隐式狄利克雷分布）首先由 David M Blei、吴恩达和 Michael I Jordan 于 2003 年提出，目前在文本挖掘领域，包括文本主题识别、文本分类以及文本相似度计算方面都有应用。LDA 是一种非监督机器学习技术，能够识别大规模文档集或语料库中潜在的主题信息，同时还能够预测推断一篇新的文档和哪些主题相关。LDA 模型现在已经成为了主题建模中的一个标准。LDA 模型自从诞生之后有了蓬勃的扩展，特别是在社会网络和社会媒体研究领域最为常见。

PLDA 是 Google 公司使用实现的并行版本的 LDA，有 MPI 和 MapReduce 两个版本，Google 将其中的 MPI 版本在 Apache 协议下发布为开源软件。目前的最新版本为 3.1。PLDA 解决了存储和计算的瓶颈，并行对于长时间的分布式计算提供了错误恢复机制。它的源代码可以在其主页 https://code.google.com/p/plda/ 下载到。

但是 PLDA 同样在内存和存储、以及扩展性方面都遇到了瓶颈，为了解决这些问题，中科院网络中心在 PLDA 软件的基础上进行了进一步的优化：一是修改了程序中数据的结构，优化了内存的使用，减少内存使用量；二是引入了 OpenMP 多线程并行，将 PLDA 增强为两级混合并行模式，提高了程序的可扩展性，使其能够在更大规模的机器上良好运行；三是增加了预处理环节，过滤掉出现频率很低的词，从而在保证训练结果准确的前提下，减少了计算量。
